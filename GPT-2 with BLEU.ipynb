{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTmZKLmMtne1XuLiTrWB0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinayakG2002/NLPlay-with-Transformers/blob/main/GPT-2%20with%20BLEU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv7WK6hUlx_l",
        "outputId": "1323a758-aa2e-4f0c-bf84-f050490b2ec7"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30q35Qosl11k"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez4MyXt-l1y2"
      },
      "source": [
        "url='https://raw.githubusercontent.com/VinayakG2002/NLPlay-with-Transformers/main/science.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY4L4GPGl1vw",
        "outputId": "251aef23-4aef-47e8-e2d4-0cb8ab4289fc"
      },
      "source": [
        "for i in range (15):\n",
        "  df['review'][i] = str(df['review'][i])\n",
        "df['review'] = df['review'].apply(lambda x: x.replace('\\n',''))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5pOH1Ynl1s0"
      },
      "source": [
        "df['length'] = df['review'].apply(len)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "9GgmLBpFl1pu",
        "outputId": "6a6cd6c9-3dac-4c8e-a15b-7e2198d4a4c0"
      },
      "source": [
        "\n",
        "df.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>review</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>HE HACKER TOURIST ventures forth across the wi...</td>\n",
              "      <td>32653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Towards the end of the summer of 1969 – a few ...</td>\n",
              "      <td>23531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>A Nation Of Echo Chambers: How The Internet Cl...</td>\n",
              "      <td>13626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Decades before the rise of social media, polar...</td>\n",
              "      <td>17928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>The World’s Most Efficient LanguagesHow much d...</td>\n",
              "      <td>11852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>In our experience the past is the past and the...</td>\n",
              "      <td>19711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>THE SOCIAL LIFE OF GENESYour DNA is not a blue...</td>\n",
              "      <td>32429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>The Biology of AttractionMuch of courtship and...</td>\n",
              "      <td>26089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Extreme chemistry: experiments at the edge of ...</td>\n",
              "      <td>21271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Key trends for property investors to watch in ...</td>\n",
              "      <td>6173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0                                             review  length\n",
              "0   1  HE HACKER TOURIST ventures forth across the wi...   32653\n",
              "1   2  Towards the end of the summer of 1969 – a few ...   23531\n",
              "2   3  A Nation Of Echo Chambers: How The Internet Cl...   13626\n",
              "3   4  Decades before the rise of social media, polar...   17928\n",
              "4   5  The World’s Most Efficient LanguagesHow much d...   11852\n",
              "5   6  In our experience the past is the past and the...   19711\n",
              "6   7  THE SOCIAL LIFE OF GENESYour DNA is not a blue...   32429\n",
              "7   8  The Biology of AttractionMuch of courtship and...   26089\n",
              "8   9  Extreme chemistry: experiments at the edge of ...   21271\n",
              "9  10  Key trends for property investors to watch in ...    6173"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNAYkSqyl1mj"
      },
      "source": [
        "\n",
        "from transformers import GPT2LMHeadModel , GPT2Tokenizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdlPWy5gl1jM"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large') \n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-large' , \n",
        "pad_token_id = tokenizer.eos_token_id)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWTKQY38l1f4"
      },
      "source": [
        "df['ref'] = df['review'].apply(lambda x: tokenizer.decode(tokenizer.encode(x[:2000],return_tensors='pt')[0]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sddU7hDl1c0",
        "outputId": "24153fc8-b8bc-4463-e759-c3e9e49daf0e"
      },
      "source": [
        "def gen(x):\n",
        "  input_ids = tokenizer.encode(x[:200],return_tensors='pt')\n",
        "  output = model.generate(input_ids, max_length = 2000, num_beams = 5,no_repeat_ngram_size  = 2,early_stopping = True)\n",
        "  return output\n",
        "\n",
        "df['gen'] = df['ref'].apply(gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqQ5OE3el1Z2"
      },
      "source": [
        "from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu, sentence_bleu\n",
        "\n",
        "\n",
        "def bleu(ref, gen):\n",
        "    ''' \n",
        "    calculate pair wise bleu score. uses nltk implementation\n",
        "    Args:\n",
        "        references : a list of reference sentences \n",
        "        candidates : a list of candidate(generated) sentences\n",
        "    Returns:\n",
        "        bleu score(float)\n",
        "    '''\n",
        "    ref_bleu = []\n",
        "    gen_bleu = []\n",
        "    for l in gen:\n",
        "        gen_bleu.append(l.split())\n",
        "    for i,l in enumerate(ref):\n",
        "        ref_bleu.append([l.split()])\n",
        "    cc = SmoothingFunction()\n",
        "    score_bleu = corpus_bleu(ref_bleu, gen_bleu, weights=(0, 1, 0, 0), smoothing_function=cc.method4)\n",
        "    return score_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgNkNsHAl1Wz"
      },
      "source": [
        "x = bleu(list(df['ref']),list(df['gen'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}